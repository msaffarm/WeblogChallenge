{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "CURRENT_DIR = Path(os.path.dirname(''))\n",
    "UTILS_DIR = CURRENT_DIR / '../utils'\n",
    "DATA_DIR = CURRENT_DIR / '../data'\n",
    "# add UTILS_DIR to system path so we can use it\n",
    "sys.path.append(UTILS_DIR.absolute().as_posix())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf().set(\"spark.executor.memory\", \"4g\").set('spark.driver.memory', '10g').\\\n",
    "                    setMaster('local[20]').setAppName('WebLogAnalysis')\n",
    "sc = SparkContext(conf = conf)\n",
    "\n",
    "# import spark.sql\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gzip: /home/jovyan/work/experiments/../data/2015_07_22_mktplace_shop_web_log_sample.log.gz: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# unpack the data if not already done\n",
    "comp_data_path = DATA_DIR / '2015_07_22_mktplace_shop_web_log_sample.log.gz'\n",
    "comp_data_path_str = comp_data_path.absolute().as_posix()\n",
    "! gunzip $comp_data_path_str\n",
    "data_path = (DATA_DIR / '2015_07_22_mktplace_shop_web_log_sample.log').absolute().as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['timestamp', 'elb', 'client_port', 'backend_port', 'request_processing_time',\n",
    "               'backend_processing_time', 'response_processing_time', 'elb_status_code',\n",
    "                'backend_status_code', 'received_bytes', 'sent_bytes', 'request',\n",
    "                'user_agent', 'ssl_cipher', 'ssl_protocol'\n",
    "               ]\n",
    "colname_to_idx = dict(zip(column_names, range(len(column_names))))\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('timestamp', TimestampType(), False),\n",
    "    StructField('elb', StringType(), False),\n",
    "    StructField('client_port', StringType(), False),\n",
    "    StructField('backend_port', StringType(), False),\n",
    "    StructField('request_processing_time', DoubleType(), False),\n",
    "    StructField('backend_processing_time', DoubleType(), False),\n",
    "    StructField('response_processing_time', DoubleType(), False),\n",
    "    StructField('elb_status_code', StringType(), False),\n",
    "    StructField('backend_status_code', StringType(), False),\n",
    "    StructField('received_bytes', IntegerType(), False),\n",
    "    StructField('sent_bytes', IntegerType(), False),\n",
    "    StructField('request', StringType(), False),\n",
    "    StructField('user_agent', StringType(), False),\n",
    "    StructField('ssl_cipher', StringType(), False),\n",
    "    StructField('ssl_protocol', StringType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil.parser\n",
    "import re\n",
    "\n",
    "def parse_line(line):\n",
    "\n",
    "    pattern = r'^(.*?)\"(.*?)\" \"(.*?)\"(.*?)$'\n",
    "    parts = re.findall(pattern,line)[0]\n",
    "    all_data_fields = parts[0].strip().split() + [parts[1].strip()] + [parts[2].strip()] + parts[3].strip().split()\n",
    "\n",
    "    # convert timestamp to datetime\n",
    "    all_data_fields[colname_to_idx['timestamp']] = dateutil.parser.parse(all_data_fields[colname_to_idx['timestamp']])\n",
    "    # convert request_processing_time, backend_processing_time, response_processing_time to float\n",
    "    all_data_fields[colname_to_idx['request_processing_time']] = float(all_data_fields[colname_to_idx['request_processing_time']])\n",
    "    all_data_fields[colname_to_idx['backend_processing_time']] = float(all_data_fields[colname_to_idx['backend_processing_time']])\n",
    "    all_data_fields[colname_to_idx['response_processing_time']] = float(all_data_fields[colname_to_idx['response_processing_time']])\n",
    "    # convert bytes to integer\n",
    "    all_data_fields[colname_to_idx['received_bytes']] = int(all_data_fields[colname_to_idx['received_bytes']])\n",
    "    all_data_fields[colname_to_idx['sent_bytes']] = int(all_data_fields[colname_to_idx['sent_bytes']])    \n",
    "    \n",
    "    return all_data_fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text_file = sc.textFile(data_path)\n",
    "parts = raw_text_file.map(lambda line: parse_line(line))\n",
    "raw_data_df = spark.createDataFrame(parts, schema).cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1158500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sessionize dataset\n",
    "Sessionize the web log by IP. Sessionize = aggregrate all page hits by visitor/IP during a session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql as pysql\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add IP to columns\n",
    "fn = F.udf(lambda x:x.split(':')[0], StringType())\n",
    "df_with_ip = raw_data_df.withColumn('IP', fn(raw_data_df.client_port))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add URL to columns\n",
    "def get_url_from_request(request):\n",
    "    if request=='- - - ':\n",
    "        return request\n",
    "    else:\n",
    "        return request.split()[1]\n",
    "\n",
    "url_udf = F.udf(lambda x:get_url_from_request(x), StringType())\n",
    "complete_df = df_with_ip.withColumn('URL', url_udf(df_with_ip.request))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session time is set to 15 mins\n",
    "session_time_seconds = 15*60\n",
    "\n",
    "# define session window function!\n",
    "time_diff_fn = pysql.Window.partitionBy('IP').orderBy('timestamp')\n",
    "\n",
    "# add previous timestamp to each row\n",
    "df_temp1 = complete_df.withColumn('prevtimestamp', F.lag('timestamp',1).over(time_diff_fn))\n",
    "\n",
    "# compute the difference between timestamps for each row\n",
    "df_temp2 = df_temp1.withColumn('diff',\\\n",
    "                 F.when(F.isnull(F.unix_timestamp(df_temp1.timestamp)-F.unix_timestamp(df_temp1.prevtimestamp)),0)\\\n",
    "                 .otherwise(F.unix_timestamp(df_temp1.timestamp)-F.unix_timestamp(df_temp1.prevtimestamp)))\n",
    "\n",
    "# set flag for each row if new session is detected!\n",
    "df_temp3 = df_temp2.withColumn('is_new_session', F.when(df_temp2.diff > 15*60, 1).otherwise(0))\n",
    "\n",
    "# create a session_id column for each user (IP). We need to create a window to look at all rows (for each IP)\n",
    "# from the beggining till the current row. Note that rows are sorted by timestamp.\n",
    "new_sess_window_fn = pysql.Window.partitionBy('IP').orderBy('timestamp').\\\n",
    "                  rowsBetween(pysql.Window.unboundedPreceding,pysql.Window.currentRow)\n",
    "\n",
    "df_with_session_id = df_temp3.withColumn('session_id', F.sum('is_new_session').over(new_sess_window_fn)).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average session time\n",
    "Determine the average session time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['timestamp',\n",
       " 'elb',\n",
       " 'client_port',\n",
       " 'backend_port',\n",
       " 'request_processing_time',\n",
       " 'backend_processing_time',\n",
       " 'response_processing_time',\n",
       " 'elb_status_code',\n",
       " 'backend_status_code',\n",
       " 'received_bytes',\n",
       " 'sent_bytes',\n",
       " 'request',\n",
       " 'user_agent',\n",
       " 'ssl_cipher',\n",
       " 'ssl_protocol',\n",
       " 'IP',\n",
       " 'URL',\n",
       " 'prevtimestamp',\n",
       " 'diff',\n",
       " 'is_new_session',\n",
       " 'session_id']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_session_id.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_df = df_with_session_id.select('IP','timestamp','session_id','diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_session_window_fn = pysql.Window.partitionBy('IP','session_id')\n",
    "temp = truncated_df.withColumn('session_time', F.sum('diff').over(user_session_window_fn))\n",
    "user_session_time_df = temp.drop('diff','timestamp').drop_duplicates(['IP','session_id'])\n",
    "user_session_time_df.agg({'session_time':'avg'}).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine unique URL visits per session\n",
    "Determine unique URL visits per session. To clarify, count a hit to a unique URL only once per session.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df = df_with_session_id.select('IP','session_id','URL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+--------------------+-----------+\n",
      "|          IP|session_id|                 URL|unique_urls|\n",
      "+------------+----------+--------------------+-----------+\n",
      "|1.186.143.37|         0|https://paytm.com...|          2|\n",
      "|1.186.143.37|         0|https://paytm.com...|          2|\n",
      "|1.187.164.29|         0|https://paytm.com...|          8|\n",
      "|1.187.164.29|         0|https://paytm.com...|          8|\n",
      "|1.187.164.29|         0|https://paytm.com...|          8|\n",
      "|1.187.164.29|         0|https://paytm.com...|          8|\n",
      "|1.187.164.29|         0|https://paytm.com...|          8|\n",
      "|1.187.164.29|         0|https://paytm.com...|          8|\n",
      "|1.187.164.29|         0|https://paytm.com...|          8|\n",
      "|1.187.164.29|         0|https://paytm.com...|          8|\n",
      "|1.187.164.29|         0|https://paytm.com...|          8|\n",
      "|  1.22.41.76|         0|https://paytm.com...|          5|\n",
      "|  1.22.41.76|         0|https://paytm.com...|          5|\n",
      "|  1.22.41.76|         0|https://paytm.com...|          5|\n",
      "|  1.22.41.76|         0|https://paytm.com...|          5|\n",
      "|  1.22.41.76|         0|https://paytm.com...|          5|\n",
      "|  1.22.41.76|         0|https://paytm.com...|          5|\n",
      "|  1.22.41.76|         0|https://paytm.com...|          5|\n",
      "|  1.22.41.76|         0|https://paytm.com...|          5|\n",
      "| 1.23.208.26|         0|https://paytm.com...|          5|\n",
      "+------------+----------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url_window_fn = pysql.Window.partitionBy('IP','session_id')\n",
    "url_df.withColumn('unique_urls', F.size(F.collect_set('URL').over(url_window_fn))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the most engaged users\n",
    "Find the most engaged users, ie the IPs with the longest session times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+------------+\n",
      "|             IP|session_id|session_time|\n",
      "+---------------+----------+------------+\n",
      "|   27.120.106.3|         1|       66299|\n",
      "|117.255.253.155|         1|       57423|\n",
      "|   14.139.69.64|         1|       57386|\n",
      "| 98.230.153.173|         1|       57314|\n",
      "|  103.24.125.26|         1|       57286|\n",
      "| 150.228.40.140|         1|       57214|\n",
      "|  66.249.82.186|         1|       57127|\n",
      "| 37.228.107.126|         1|       55503|\n",
      "| 168.235.194.47|         1|       55476|\n",
      "|    1.39.63.157|         1|       55353|\n",
      "|     1.39.35.89|         1|       55350|\n",
      "|  163.47.14.170|         1|       55349|\n",
      "|  163.47.12.254|         1|       55325|\n",
      "| 107.167.109.55|         1|       55313|\n",
      "|     1.39.32.67|         1|       55295|\n",
      "|107.167.107.108|         1|       55293|\n",
      "|    1.39.12.226|         1|       55289|\n",
      "| 107.167.107.41|         1|       55187|\n",
      "| 37.228.104.174|         1|       55183|\n",
      "| 192.20.246.138|         1|       55163|\n",
      "|    59.177.1.75|         1|       55151|\n",
      "|   112.79.38.69|         1|       55146|\n",
      "|    1.39.60.122|         1|       55135|\n",
      "|112.133.229.113|         1|       55134|\n",
      "|    1.39.46.165|         1|       55121|\n",
      "|101.221.134.218|         1|       55103|\n",
      "| 37.228.106.100|         1|       55095|\n",
      "| 107.167.103.82|         1|       55062|\n",
      "| 49.206.245.152|         1|       55054|\n",
      "|   14.99.158.95|         1|       55034|\n",
      "|   27.6.176.122|         1|       55012|\n",
      "|  37.228.105.94|         1|       54999|\n",
      "|103.232.128.226|         1|       54316|\n",
      "| 14.139.160.234|         1|       54230|\n",
      "|106.206.149.203|         1|       54184|\n",
      "| 182.71.230.154|         1|       54181|\n",
      "|     1.38.21.92|         1|       54169|\n",
      "|    103.25.0.50|         1|       54161|\n",
      "|   42.99.164.64|         1|       54154|\n",
      "|    1.39.13.164|         1|       54149|\n",
      "+---------------+----------+------------+\n",
      "only showing top 40 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_session_time_df.orderBy('session_time',ascending=False).show(40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
